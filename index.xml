<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Science Portfolio on Home</title>
    <link>https://a-c-a-f.github.io/Ariel_Portfolio/</link>
    <description>Recent content in Data Science Portfolio on Home</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 28 Jul 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://a-c-a-f.github.io/Ariel_Portfolio/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Statistical Data Vizz using Plotly</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-17/</link>
      <pubDate>Thu, 28 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-17/</guid>
      <description>In this project we will explore plotly express to visually statistical plots such as box plots, histograms, heat maps, density maps, contour plots and violent plots.
Some important background about plotly package.
 The plotly Python package empowers anyone to create, manipulate and render graphical figures. The figures are represented by data structures referred to as figures. The rendering process uses the Plotly.js JavaScript library under the hood but you never need to use Java directly.</description>
    </item>
    
    <item>
      <title>Linear Regression</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-25/</link>
      <pubDate>Sat, 23 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-25/</guid>
      <description>In this project, we will learn how to implement Linear Regression using Python and Numpy. Linear Regression is an important, fundamental concept if you want break into Machine Learning and Deep Learning.
Data Source: Refer to notebook.
Below are the key objectives of this project:  Create a linear model, and implement gradient descent. Train the linear model to fit given data with gradient descent.  Below is the summary of the tasks performed in this project:  Task 1: Introduction Task 2: Dataset Task 3: Initialize Parameters Task 4: Forward Pass Task 5: Compute Loss Task 6: Backward Pass Task 7: Update Parameters Task 8: Training Loop Task 9: Predictions  You can find the source data and my codes in my Project&amp;rsquo;s Repository below:</description>
    </item>
    
    <item>
      <title>EDA on Insurance Dataset</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-14/</link>
      <pubDate>Wed, 20 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-14/</guid>
      <description>In this project, we will learn practically how to create and apply graphical techniques in Exploratory Data Analysis (EDA). The dataset that we will be working on is about insurance record containing some features like age, gender and BMI and the region, and if the person is a smoker on non smoker and charges.
Data Source: https://www.kaggle.com/datasets/joudalnsour/data-visualizatiion
Below are the key objectives of this project:  Understanding the concept of Exploratory Data Analysis.</description>
    </item>
    
    <item>
      <title>Image Denoising with Autoencoders</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-24/</link>
      <pubDate>Wed, 20 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-24/</guid>
      <description>In this project, we will learn the basics of image noise reduction with auto-encoders. Auto-encoding is an algorithm to help reduce dimensionality of data with the help of neural networks.
Data Source: MNIST dataset
Below are the key objectives of this project:  Develop an understanding of Auto-encoders. Be able to apply Image Noise Reduction with Auto-encoders.  Below is the summary of the tasks performed in this project:  Task 1: An introduction to the problem, as well as a summary of the imports we will need.</description>
    </item>
    
    <item>
      <title>Dimensionality Reduction</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-23/</link>
      <pubDate>Mon, 18 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-23/</guid>
      <description>In this project, we will introduce the theory behind an autoencoder (AE), its uses, and its advantages over PCA, a common dimensionality reduction technique.
Data Source: We will use the make_blobs function from sklearn.dataset to create our own dataset.
Below are the key objectives of this project:  How to create a dummy dataset of high dimensionality, and reduce its dimensionality using PCA. How an autoencoder works, and how it is essentially a nuanced neural network.</description>
    </item>
    
    <item>
      <title>CIFAR-10 Image Classification</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-22/</link>
      <pubDate>Fri, 08 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-22/</guid>
      <description>In this project, we will build, train, and test a deep neural network model to classify low-resolution images containing airplanes, cars, birds, cats, ships, and trucks in Keras and Tensorflow 2.0. We will use Cifar-10 which is a benchmark dataset that stands for the Canadian Institute For Advanced Research (CIFAR) and contains 60,000 32x32 color images
Data Source: https://www.cs.toronto.edu/~kriz/cifar.html
Below are the key objectives of this project:  Understand the fundamentals of Convolutional Neural Networks (CNNs) Build, train and test Convolutional Neural Networks in Keras and Tensorflow 2.</description>
    </item>
    
    <item>
      <title>Basic-Image-Classification</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-21/</link>
      <pubDate>Thu, 07 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-21/</guid>
      <description>In this project, we will create and train a model that takes an image of a hand written digit as input and predicts the class of that digit, that is, it predicts the digit or it predicts the class of the input image. Through this project, will learn the basics of using Keras with TensorFlow as its backend and use it to solve a basic image classification problem.
Data Source: MNIST data</description>
    </item>
    
    <item>
      <title>ML Algorithms</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-20/</link>
      <pubDate>Wed, 06 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-20/</guid>
      <description>In this project, we will train several classification algorithms. Machine learning algorithms help companies analyze customer attrition rate based on several factors which includes various services subscribed by the customers, tenure rate, gender, senior citizen, payment method, etc..
Data Source: https://www.kaggle.com/datasets/blastchar/telco-customer-churn
Below are the key objectives of this project:  Understand the theory and intuition behind Logistic Regression, Support Vector Machine, Random Forest, K-Nearest Neighbor, and Naive Bayes Classifier models.</description>
    </item>
    
    <item>
      <title>Artificial Neural Nets</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-19/</link>
      <pubDate>Fri, 01 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-19/</guid>
      <description>In this project, we will build and train a simple deep neural network model to predict the likelihood of a liability customer (depositor) buying personal loans based on customer features like age, experience, income, locations, family, education, existing mortgage, and credit card, etc..
Lenddo is a leading startup that uses advanced machine learning to analyze over 12,000+ features from various sources of data to predict an individual&amp;rsquo;s creditworthiness (e.g.: social media account use, geolocation data, etc.</description>
    </item>
    
    <item>
      <title>Classification Regression Models</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-18/</link>
      <pubDate>Sat, 25 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-18/</guid>
      <description>In this project, we will explore how we can develop an intepretable and explainable machine learning application on the example of classification regression models such as a Decision Tree and Random Forest Classifiers.
Data Source: https://www.kaggle.com/datasets/shikhar07/fifa-2018-dataset
Below are the key objectives of this project:  Create an intepretable machine learning application in Python. Select, run, evaluate and compare two different classification regression models. Extract, which features are the most important ones for our classification regressors.</description>
    </item>
    
    <item>
      <title>SQL Date Time Functions</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/sql/sql-7/</link>
      <pubDate>Sat, 25 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/sql/sql-7/</guid>
      <description>This project is for people who are interested in writing conditional statements and manipulating data in a database, that is retrieving data from a database to get insights using SQL.
Below are the key objectives of this project:  Understand how SQL Date Time functions works and when to use them Manipulate date-like data using different Date Time functions Manipulate data in tables using SQL SELECT statements together with Date Time functions  Below is the summary of the tasks performed in this project:  Task 1:	Retrieve data from tables in the employees database Task 2:	Use the CURRENT_DATE, CURRENT_TIME &amp;amp; CURRENT_TIMESTAMP functions to retrieve data Task 3:	Use the AGE function to retrieve data from tables in the employees database Task 4:	Use the AGE function in more real-life applications Task 5:	Use the EXTRACT function to retrieve data from tables in the employees database Task 6:	Use the EXTRACT function in more real-life applications Task 7:	Use the TO_CHAR function to convert date to strings Task 8:	Use the TO_DATE function to convert strings to date  Link to GitHub Repository.</description>
    </item>
    
    <item>
      <title>Interactive Data Visualization with Plotly</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/dashboard-vizz/python-15/</link>
      <pubDate>Fri, 24 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/dashboard-vizz/python-15/</guid>
      <description>In this project, we will understand the fundamentals of interactive data visualization using Plolty Express.
Data Source: https://www.kaggle.com/datasets/arielfelices/dataset-for-data-vizz-projects
Below is the summary of the tasks performed in this project:  Task 1: Plot Interactive Scatterplot Using Plotly Express Task 2: Plot interactive Bubble Charts Task 3: Plot Interactive Single Line Plot Task 4: Plot Multiple Interactive Line Plots Task 5: Plot Interactive Pie Charts Task 6: Plot Interactive Bar Charts Task 7: Plot Interactive Gantt Charts Task 8: Plot Interactive Sunburst  Link to GitHub Repository.</description>
    </item>
    
    <item>
      <title>Time Series Data Visualization</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/dashboard-vizz/python-14/</link>
      <pubDate>Wed, 22 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/dashboard-vizz/python-14/</guid>
      <description>In this project we&amp;rsquo;re going to talk about different data visualization techniques and the tasks that we can consider for a better understanding, exploration and analysis while working with time series datasets.
Also, in this project we are going to work with a dataset consists of data related to average daily temperature of different cities around the globe from 1995 to 2020.
Data Source: https://www.kaggle.com/datasets/subhamjain/temperature-of-all-countries-19952020
Below is the summary of the tasks performed in this project:  Task 1: Introduction about our goal in this project.</description>
    </item>
    
    <item>
      <title>Principal Component Analysis</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-13/</link>
      <pubDate>Mon, 20 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-13/</guid>
      <description>In this project, we are going to implement PCA from scratch without using any popular ML libraries like scikit learn. The data that we used is a popula ML datasets that lives on UCI repository.
Data Source: https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data
Below are the key objectives of this project:  Implement Principal Component Analysis (PCA) from scratch with NumPy and Python Conduct basic exploratory data analysis (EDA) Create simple data visualizations with Seaborn and Matplotlib  Below is the summary of the tasks performed in this project:  Task 1: Introduction to the data set and the problem overview.</description>
    </item>
    
    <item>
      <title>SQL CASE Statements</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/sql/sql-6/</link>
      <pubDate>Sun, 19 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/sql/sql-6/</guid>
      <description>This project is for people who are interested in writing conditional statements and manipulating data in a database, that is retrieving data from a database to get insights using SQL.
Below are the key objectives of this project:  Understand the function of CASE statements in SQL Write simple CASE statements Write complex CASE statements  Below is the summary of the tasks performed in this project:  Task 1: The SQL CASE statement Task 2: Adding multiple conditions to a CASE statement Task 3: The CASE Statement and Aggregate Functions Task 4: The CASE Statement and SQL Joins Task 5: The CASE Statement together with Aggregate Functions and Joins Task 6: Transposing data using the CASE clause  Link to GitHub Repository.</description>
    </item>
    
    <item>
      <title>SQL String Functions</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/sql/sql-5/</link>
      <pubDate>Sun, 19 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/sql/sql-5/</guid>
      <description>This project is for people who are interested in creating and manipulating data in a database, that is, retrieving data from a database to get summaries and insights using SQL.
Below are the key objectives of this project:  Understand how string functions work and when to use them Clean data using different string functions Manipulate data using SQL SELECT statements together with string functions  Below is the summary of the tasks performed in this project:  Task 1: Create and Retrieve additional tables Task 2: LENGTH, LEFT, RIGHT Task 3: UPPER &amp;amp; LOWER Task 4: REPLACE Task 5: TRIM, RTRIM, LTRIM Task 6: Concatenation Task 7: SUBSTRING Task 8: String Aggregation Task 9: COALESCE  Link to GitHub Repository.</description>
    </item>
    
    <item>
      <title>Regression-using-TensorFlow</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-17/</link>
      <pubDate>Thu, 16 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-17/</guid>
      <description>In this project, We are looking to solve a regression problem. With the help of a neural network model and some data in a regression task, we train the neural network to predict a continuous value, given a set of input features. This is different from classification. In classification problems, we train a model to predict discrete values or classes.
Data Source: https://www.kaggle.com/datasets/mubin2509/housepricedata
Given some data with these features and the corresponding price for various houses, we will create and train a model that will give us fairly accurate price predictions for new, unseen data.</description>
    </item>
    
    <item>
      <title>Hierarchical Data Analysis</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-12/</link>
      <pubDate>Mon, 13 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-12/</guid>
      <description>The data set that we&amp;rsquo;re going to work with contains some hierarchical data about different products sold in different stores in different cities in Mexico.
Data Source: https://www.kaggle.com/datasets/arielfelices/acaf-dataset-collection?select=Miexico_hierarchical_dataset.csv
Below are the key objectives of this project:  Learn how to analyze Hierarchical Data. Learn how to analyze data using different visualization techniques. Learn the of concept of Data Granularity. Learn how to use different levels of granularity to answer some analytical question.</description>
    </item>
    
    <item>
      <title>Logistic Regression with Python</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-16/</link>
      <pubDate>Fri, 10 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-16/</guid>
      <description>Unlike in the case of linear regression, where we&amp;rsquo;re trying to predict a real and continuous valued output, logistic regression is a classification algorithm and it tries to predict a discrete set of class labels for the given input.
Data Source: https://www.kaggle.com/datasets/arielfelices/acaf-dataset-collection?select=DMV_Written_Tests.csv
Our dataset is DMV_Written_Tests.csv. This dataset is comprised of written test scores. We will be trying to predict if a person with those test scores passed or failed.</description>
    </item>
    
    <item>
      <title>Building Candlestick Charts with Tableau</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/dashboard-vizz/vizz_project-6/</link>
      <pubDate>Thu, 09 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/dashboard-vizz/vizz_project-6/</guid>
      <description>Below are the key objectives of this project:  Use Python YFinance to extract stock price data Use Tableau to build a japanese candlestick chart  Below is the summary of the tasks performed in this project:  Task 1: Extracting stock price data with YFinance Task 2: Preparing data and calculated fields Task 3: Building and formatting Gantt bar chart Task 4: Turning Gantt bar into candlestick chart Task 5: Analyzing candlestick chart  Link to the chart.</description>
    </item>
    
    <item>
      <title>SQL Data Definition and Manipulation</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/sql/sql-4/</link>
      <pubDate>Thu, 09 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/sql/sql-4/</guid>
      <description>This project is for people who are interested in creating and manipulating data in a database, that is, retrieving data from a database to get summaries and insights using SQL.
Below are the key objectives of this project:  Using SQL data definition statements for various data definition tasks such as creating a database, tables. Using SQL data manipulation statements for various data manipulation tasks such as updating records of a table.</description>
    </item>
    
    <item>
      <title>SQL Subqueries</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/sql/sql-3/</link>
      <pubDate>Thu, 09 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/sql/sql-3/</guid>
      <description>This project is for people who are interested in manipulating data in a database, that is, retrieving data from a database to get summaries and insights using SQL.
Below are the key objectives of this project:  Use subqueries in the WHERE clause Use subqueries in the FROM clause Use subqueries in the SELECT clause  Below is the summary of the tasks performed in this project:  Task 1: Getting Started: Retrieve data from tables in the employees database.</description>
    </item>
    
    <item>
      <title>Linear Regression Model in R</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/collections/r-3/</link>
      <pubDate>Sun, 05 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/collections/r-3/</guid>
      <description>This project is for people who are interested in building a linear regression model on real world data set and analyze the model&amp;rsquo;s performance in R.
Data Source: https://www.kaggle.com/datasets/hashroot97/carpriceprediction
Below are the key objectives of this project:  How to load and clean a real world data set. How to build a linear regression model and create various plots to analyze the model&amp;rsquo;s performance. How to predict future values using this model.</description>
    </item>
    
    <item>
      <title>Statistics in Python (ANOVA)</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-11/</link>
      <pubDate>Sat, 04 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-11/</guid>
      <description>This project is for people who are interested in statistics, particularly carrying our statistical analysis in Python. In this project we will be focusing on the data set from the World Bank, which is on education, specifically around the percentage of females which are unemployed in different country groups. We will use python to create plots so that we can visualize our results. We will also be performing ANOVA on different groups and using box plots to visualize the results of that analysis.</description>
    </item>
    
    <item>
      <title>Deep Learning for Real Estate Price Prediction</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-15/</link>
      <pubDate>Fri, 03 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-15/</guid>
      <description>In this project, we will predict real estate prices using artificial neural networks. Dataset includes house sale prices for King County in USA and homes that are sold in the time period between May 2014 and May 2015.
Data Source: https://www.kaggle.com/harlfoxem/housesalesprediction
Below is the summary of the tasks performed in this project:  Task 1: Understand the Problem Statement and Business Case Task 2: Import Libraries and Datasets Task 3: Perform Data Visualization Task 4: Perform Data Cleaning and Feature Engineering Task 5: Train a Deep Learning Model with Limited Number of Features Task 6: Evaluate Trained Deep Learning Model Performance Task 7: Train and Evaluate a Deep Learning Model with Increased Number of Features  You can find the source data and my codes in any of my Project&amp;rsquo;s Repositories below:</description>
    </item>
    
    <item>
      <title>Getting Started with Power BI Desktop</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/dashboard-vizz/vizz_project-5/</link>
      <pubDate>Fri, 03 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/dashboard-vizz/vizz_project-5/</guid>
      <description>This is an introductory project for learning how to use Power BI Desktop. The data that we&amp;rsquo;re working with comes from UC Machine Learning Repository and this is a data set of credit card defaults that happened in Taiwan back in 2005.
Data Source: https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients
Below are the key objectives of this project:  Import and transform data with Power BI Desktop Visualize date and create reports with Power BI Desktop  Below is the summary of the tasks performed in this project:  Task 1: Importing the Data Task 2: Fixing the Column Names Task 3: Transforming the Data Task 4: Getting Started with Reports Task 5: Defaults by Education Level Task 6: Defaults by States Task 7: Defaulter Ratio and Slicing the Data  Note:</description>
    </item>
    
    <item>
      <title>Sentimental Analysis Using Python</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-10/</link>
      <pubDate>Tue, 31 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-10/</guid>
      <description>In this project, we are going to use a dataset consisting of the data related to tweets from 24th of July 2020 to 30th August 2020 with Covid19 hashtags. We&amp;rsquo;re going to use python to apply sentiment analysis on the tweets to see people reactions to the pandemic during the mentioned period.
Data Source: https://www.kaggle.com/datasets/gpreda/covid19-tweets
We are going to labelize each of the tweets with positive, negative and neutral labels.</description>
    </item>
    
    <item>
      <title>Exploratory Data Analysis (EDA) in R</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/collections/r-2/</link>
      <pubDate>Sun, 29 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/collections/r-2/</guid>
      <description>Project Objectives:  Perform EDA by plotting qualitative variables Perform EDA by plotting quantitative variables  Data Source can be found in the links below:
 mpg.csv mpg data dictionary msleep.csv msleep data dictionary  Project Structure  Task 1: Getting Started Task 2: Import &amp;amp; Explore Data sets Task 3: Plotting a categorical variable Task 4: Plotting a numeric variable Task 5: Plotting a Numerical and Categorical Variable Task 6: Plotting two variables Task 7: Plotting three variables  The Markdown is titled EDA in R.</description>
    </item>
    
    <item>
      <title>Python and Networkx</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-14/</link>
      <pubDate>Sat, 28 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-14/</guid>
      <description>In this project, we&amp;rsquo;re going to work with Facebook Friends Network graph. In this graph, each nodes represent a Facebook account, and the edge between two nodes indicate that those two accounts are friends. We are going to load this data set and visualized it using Python networkX module. The goal of this analysis is to explore some important characteristics of this graph, such as finding most important nodes on the graph.</description>
    </item>
    
    <item>
      <title>Data Analysis Using Seaborn and Python </title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-9/</link>
      <pubDate>Fri, 27 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-9/</guid>
      <description>In this project, we will apply various graphical techniques using Seaborn to analyze worldwide box office revenue.
Below are the key objectives of this project:  Produce data visualizations with Seaborn. Apply graphical techniques used in exploratory data analysis (EDA).  Below is the summary of the tasks performed in this project:  Task 1: Data Loading and Exploration Task 2: Visualizing the Target Distribution Task 3: Comparing Film Revenue to Budget Task 4: Do Official Homepages Impact Revenue?</description>
    </item>
    
    <item>
      <title>Neural Network Visualizer Web App</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-13/</link>
      <pubDate>Wed, 18 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-13/</guid>
      <description>In this project, we will use a simple neural network with two hidden layers and one output layer. We will visualized the output values of only nodes of all these layers. Through this project, we will learn how to create a simple server, that flask to serve our neural network model for inference, a simple web application with streamlit.
Below are the key objectives of this project:  Create a model server with Flask and Keras Create a web application with Streamlit Utilize Keras&amp;rsquo; functional API  Below is the summary of the tasks performed in this project:  Task 1: Load Libraries and Data Task 2: Data Normalization Task 3: Create and Train a Neural Network Model Task 4: Create a Model Server with Flask Task 5: Create a Streamlit Web Application  You can find the source data and my codes in my Project&amp;rsquo;s GitHub Repository.</description>
    </item>
    
    <item>
      <title>Statistical Analysis using Python Numpy</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-6/</link>
      <pubDate>Sat, 14 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-6/</guid>
      <description>The data set that we&amp;rsquo;re going to work with is a dataset from Kaggle, Student Performance Dataset.
Data Source: https://www.kaggle.com/datasets/barkhaverma/student-performance-dataset
Below are the key objectives of this project:  Create an Adjacency List using a Python Dictionary where each entry is a List. Add the Python function to find the shortest paths to each vertex from the source vertex. Add the function to populate the adjacency list of edges from a file using a Python Dictionary container.</description>
    </item>
    
    <item>
      <title>Calculating Descriptive Statistics in R</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/collections/r-1/</link>
      <pubDate>Thu, 12 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/collections/r-1/</guid>
      <description>Project Objectives:  Calculate basic descriptive statistics for qualitative variables Calculate basic descriptive statistics for quantitative variables Check the distribution of quantitative variables  Data Source can be found in the links below:
 mpg.csv mpg data dictionary msleep.csv msleep data dictionary  Project Structure  Task 1: Getting Started Task 2: Import Packages &amp;amp; the dataset Task 3: Frequency of categorical variables Task 4: Univariate statistics for univariate variables - Part I Task 5: Univariate statistics for univariate variables - Part II Task 6: Distribution of Quantitative Variables Task 7: Bivariate statistics for variables  The Book Code can be found at the document &amp;ldquo;Calculating-Basic-Descriptive-in-R.</description>
    </item>
    
    <item>
      <title>SQL Joins</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/sql/sql-2/</link>
      <pubDate>Thu, 12 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/sql/sql-2/</guid>
      <description>This project is for people who are interested in manipulating data in a database, that is, retrieving data from a database to get summaries and insights using SQL.
Below are the key objectives of this project:  Retrieve desired result set using the different types of joins in SQL Join more than two tables in a database using SQL Joins  Below is the summary of the tasks performed in this project:  Task 1: Getting Started: Understand concepts of SQL Joins.</description>
    </item>
    
    <item>
      <title>Sentiment Analysis Using NLP</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-12/</link>
      <pubDate>Wed, 11 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-12/</guid>
      <description>In this project, we will build a machine learning model to analyze thousands of reviews to predict customer sentiment. Artificial Intelligence and Machine Learning-based sentiment analysis is crucial for companies to automatically predict whether their customers are happy or not. This project is important and directly applicable to any company that has online presence. These algorithms could be used to automatically detect customer sentiment from their reviews.
Data Source: https://www.</description>
    </item>
    
    <item>
      <title>Stock Returns Heatmap</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/dashboard-vizz/vizz_project-4/</link>
      <pubDate>Mon, 09 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/dashboard-vizz/vizz_project-4/</guid>
      <description>In this project, I focused only on three learning objectives:
 Extract stock data using Google Finance Build a Heat and Treemap in Tableau Build a stock returns dashboard in Tableau  Below are the tasks performed in this project:
 Task 1: Importing stock price data using Google Finance Task 2: Importing market cap data using Google Finance Task 3: Preparing data for transferring Task 4: Transferring data to Tableau Task 5: Setting up columns and rows Task 6: Creating a treemap Task 7: Creating a dashboard  You can find and explore the dashboard in this link.</description>
    </item>
    
    <item>
      <title>Exploratory Data Analysis vs. Confirmatory Data Analysis</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-5/</link>
      <pubDate>Sun, 08 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-5/</guid>
      <description>The data set that we&amp;rsquo;re going to work with is a dataset containing information about product sales in the US.
Data Source: https://www.kaggle.com/datasets/arielfelices/acaf-dataset-collection?select=Product+Sales+in+US.csv
Below are the key objectives of this project:  Understand and apply Exploratory Data Analysis. Build different Data visualizations. Apply different exploration techniques based on the data at hand. Define and apply the concept of Confirmatory Data Analysis.  Below is the summary of the tasks performed in this project:  Task 1: Understanding EDA; Load Libraries; Load Data.</description>
    </item>
    
    <item>
      <title>EDA on Supermarket-sales dataset</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-4/</link>
      <pubDate>Sat, 07 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-4/</guid>
      <description>About the Dataset Data Source: https://www.kaggle.com/aungpyaeap/supermarket-sales
Context
The growth of supermarkets in most populated cities are increasing and market competitions are also high. The dataset is one of the historical sales of supermarket company which has recorded in 3 different branches for 3 months data.
Data Dictionary
 Invoice id: Computer generated sales slip invoice identification number Branch: Branch of supercenter (3 branches are available identified by A, B and C).</description>
    </item>
    
    <item>
      <title>Support Vector Machine Classification in Python</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-11/</link>
      <pubDate>Wed, 04 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-11/</guid>
      <description>In this project, we will build a support vector machine (SVM) algorithm in python with classification. We will try to predict whether a customer will purchase a particular car in the future given his age and current estimated salary. The datasaet contains the following features:
 User ID Gender Age EstimatedSalary Purchased (means if the person purchased a car before)  Data Source: https://www.kaggle.com/datasets/arielfelices/acaf-dataset-collection
Below are the key objectives of this project:  Understand the basics of Support Vector Machines in Classification using a real world example.</description>
    </item>
    
    <item>
      <title>Resume Selector</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-9/</link>
      <pubDate>Sun, 01 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-9/</guid>
      <description>In this project, we will build a naïve based model to predict whether given resume text is flagged or not. Simply put, if the resume is flagged, that means that the applicant is invited to interview.
Data Source: https://www.kaggle.com/samdeeplearning/deepnlp
Below are the key objectives of this project:  Apply python libraries to import and visualize datasets Perform exploratory data analysis and plot word-cloud Perform text data cleaning such as removing punctuation and stop words Perform tokenization using count vectorizer Train Naïve Bayes classifier models using Scikit-Learn to perform classification Evaluate the performance of trained Naïve Bayes Classifier model using confusion matrices  Below is the summary of the tasks performed in this project:  Task 1: Understand the Problem Statement and Business Case Task 2: Import libraries and datasets Task 3: Perform exploratory data analysis Task 4: Perform data cleaning Task 5: Visualize cleaned datasets Task 6: Prepare the data by applying count vectorization Task 7: Train a Naïve Bayes classifier model Task 8: Assess trained model performance  You can find the source data and my codes in any of my Project&amp;rsquo;s Repositories below:</description>
    </item>
    
    <item>
      <title>Predicting the Weather</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-10/</link>
      <pubDate>Fri, 29 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-10/</guid>
      <description>In this project, we&amp;rsquo;re going to work with a set of data that comes from the Australian government. This contains nearly nine years&amp;rsquo; worth of daily weather data from a station in Perth.
Data Source: https://www.kaggle.com/datasets/arielfelices/weatherperth
Below is the summary of the tasks performed in this project:  Task 1: Load a dataset from file Task 2: Process a dataset to make it compatible with a neural network Task 3: Split our dataset into training and testing sets Task 4: Train a neural network and make predictions Task 5: Optimize a neural network  You can find the source data and my codes in any of my Project&amp;rsquo;s Repositories below:</description>
    </item>
    
    <item>
      <title>Support Vector Machines in Python</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-8/</link>
      <pubDate>Wed, 27 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-8/</guid>
      <description>In this lesson we will built this Support Vector Machine for classification using scikit-learn and the Radial Basis Function (RBF) Kernel. Our training data set contains continuous and categorical data from the UCI Machine Learning Repository to predict whether or not a patient has heart disease.
Below are the key objectives of this project:  Importing data into, and manipulating a pandas dataframe. Identifying and dealing with missing data. Formatting the data for a support vector machine, including One-Hot Encoding Optimizing parameters for the radial basis function and classification Building, evaluating, drawing and interpreting a support vector machine  Below is the summary of the tasks performed in this project:  Task 1: Import the modules that will do all the work Task 2: Import the data Task 3: Missing Data Part 1: Identifying Missing Data Task 4: Missing Data Part 2: Dealing With Missing Data Task 5: Format Data Part 1: Split the Data into Dependent and Independent Variables Task 6: Format the Data Part 2: One-Hot Encoding Task 7: Format the Data Part 3: Centering and Scaling Task 8: Build A Preliminary Support Vector Machine Task 9: Optimize Parameters with Cross Validation Task 10: Building, Evaluating, Drawing, and Interpreting the Final Support Vector Machine  You can find the source data and my codes in any of my Project&amp;rsquo;s Repositories below:</description>
    </item>
    
    <item>
      <title>Learn Data Analysis with Pandas Part 5</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-2/</link>
      <pubDate>Tue, 26 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-2/</guid>
      <description>Pandas is a super powerful, fast, flexible and easy to use open source data analysis tool.
This dataset is actually quite famous and it&amp;rsquo;s primarily used for training machine learning models and essentially training of machine learning models, especially natural language processing models is beyond the scope of this project. What we have here is different reviews from different customers on amazon Echo product and different ratings. The customers gave the product ratings range between one and five.</description>
    </item>
    
    <item>
      <title>SQL Data Aggregation</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/sql/sql-1/</link>
      <pubDate>Tue, 26 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/sql/sql-1/</guid>
      <description>This project is for people who are interested in manipulating data in a database, that is, retrieving data from a database to get summaries and insights using SQL.
Below are the key objectives of this project:  Retrieve data as summaries from tables of a database using SQL aggregate functions Understand how to set conditions on the result set of a query using the HAVING clause  Below is the summary of the tasks performed in this project:  Task 1: INTRODUCTION Task 2: COUNT() Task 3: SELECT DISTINCT &amp;amp; GROUP BY Task 4: HAVING Task 5: SUM() Task 6: MIN() &amp;amp; MAX() Task 7: AVG() Task 8: ROUND  You can find the source data and my codes in my Project&amp;rsquo;s GitHub Repository.</description>
    </item>
    
    <item>
      <title>Predict Employee Turnover with scikit-learn</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-7/</link>
      <pubDate>Mon, 25 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-7/</guid>
      <description>Employee turnover analytics is the process of assessing your turnover rates in an attempt to predict and reduce future employee turnover. Machine Learning models can enable companies to identify variables and features and also bonuses and incentives that predict turnover within their own organization and business.
The dataset contains employees’ profiles of a large companies where each row is a data of unique employee. The dataset is downloaded from Kaggle but initially put together by a very large multinational corporation.</description>
    </item>
    
    <item>
      <title>Fake News Detection with Machine Learning</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-6/</link>
      <pubDate>Sat, 23 Apr 2022 11:25:05 -0400</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-6/</guid>
      <description>Project Objectives In this project, I am going to focus on the following learning objectives:
 Apply python libraries to import and visualize datasets Perform exploratory data analysis and plot word-cloud Perform text data cleaning such as removing punctuation and stop words Understand the concept of tokenizer. Perform tokenizing and padding on text corpus to feed the deep learning model. Understand the theory and intuition behind Recurrent Neural Networks and LSTM Build and train the deep learning model Access the performance of the trained model  Project Structure  Task 1: Understand the Problem Statement and business case Task 2: Import libraries and datasets Task 3: Perform Feature Engineering Task 4: Perform Data Cleaning Task 5: Visualize the cleaned data Task 6: Prepare the data by tokenizing and padding Task 7: Understand the theory and intuition behind Recurrent Neural Networks and LSTM Task 8: Build and train the model Task 9: Assess trained model performance  You can find the source data and my codes in my Project&amp;rsquo;s GitHub Repository.</description>
    </item>
    
    <item>
      <title>Customer Market Segmentation</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-3/</link>
      <pubDate>Thu, 14 Apr 2022 11:25:05 -0400</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-3/</guid>
      <description>Project Objectives In this project, I am going to focus on the following learning objectives:
 Understand how to leverage the power of machine learning to transform marketing departments and perform customer segmentation. Apply Python libraries to import and visualize dataset images. Understand the theory and intuition behind k-means clustering machine learning algorithm. Learn how to obtain the optimal number of clusters using the elbow method. Apply Scikit-Learn library to find the optimal number of clusters using elbow method.</description>
    </item>
    
    <item>
      <title>Multiple Linear Regression</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-2/</link>
      <pubDate>Mon, 11 Apr 2022 11:00:59 -0400</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-2/</guid>
      <description>In this project, we will build and evaluate multiple linear regression models using Python. I will use scikit-learn to calculate the regression, while using pandas for data management and seaborn for plotting. The data for this project consists of the very popular Advertising dataset to predict sales revenue based on advertising spending through media such as TV, radio, and newspaper.
Project Objectives The key objective of this project is to learn the following skills:</description>
    </item>
    
    <item>
      <title>Titanic Survival Prediction</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-5/</link>
      <pubDate>Fri, 01 Apr 2022 11:25:05 -0400</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-5/</guid>
      <description>Project Objectives  Understand the theory and intuition behind logistic regression classifier models Build, train and test a logistic regression classifier model in Scikit-Learn Perform data cleaning, feature engineering and visualization  The sinking of the Titanic is one of the most well-known tragedies in modern history. The tragedy took place on April 15, 1912. The Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers.</description>
    </item>
    
    <item>
      <title>Pattern of Losses (Sales Superstore dataset)</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/dashboard-vizz/vizz_project-3/</link>
      <pubDate>Fri, 01 Apr 2022 10:58:08 -0400</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/dashboard-vizz/vizz_project-3/</guid>
      <description>This is one of the visualization exercises from the course &amp;ldquo;Data Visualization with Tableau Specialization&amp;rdquo; using the Sales Superstore dataset.
Feel free to visit and navigate this sample story from this link.</description>
    </item>
    
    <item>
      <title>Univariate Linear Regression</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-1/</link>
      <pubDate>Mon, 28 Mar 2022 10:58:08 -0400</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-1/</guid>
      <description>Project Objectives My objective in this project is to learn the following skills:
 Implement the gradient descent algorithm from scratch. Perform univariate linear regression with Numpy and Python. Create data visualizations and plots using matplotlib.  Project Structure Below is the summary of the tasks performed in this project:
 Task 1: Load the Data and Libraries Task 2: Visualize the Data Task 3: Compute the Cost 𝐽(𝜃) Task 4: Implement Gradient Descent from scratch in Python Task 5: Visualizing the Cost Function J(𝜃) Task 6: Plotting the Convergence Task 7: Training Data with Univariate Linear Regression Fit Task 8: Inference using the optimized 𝜃 values  You can find the source data and my codes in any of my Project&amp;rsquo;s Repositories below:</description>
    </item>
    
    <item>
      <title>Tour de France Story</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/dashboard-vizz/vizz_project-2/</link>
      <pubDate>Sat, 19 Mar 2022 10:58:08 -0400</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/dashboard-vizz/vizz_project-2/</guid>
      <description>The focus in this project are primarily on the following objectives:
 Task 1: Connect a sample data set and build line charts Task 2:	Build packed bubbles and treemap charts Task 3:	Prepare dashboards Task 4:	Create a story  Feel free to visit and navigate this sample story from this link.</description>
    </item>
    
    <item>
      <title>Visualizing Citibike Trips</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/dashboard-vizz/vizz_project-1/</link>
      <pubDate>Sat, 26 Feb 2022 10:58:08 -0400</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/dashboard-vizz/vizz_project-1/</guid>
      <description>Below are the tasks performed in this project:
 Task 1: Importing the Data  Importing the Citibike trips data. Measures and dimensions. Worksheets in Tableau.   Task 2:	Most Popular End Stations  Overview of Citibike dataset. Plot most popular end stations. Using filters in Tableau.   Task 3:	Most Popular Start Stations  Plot most popular start stations. Adding more filters.   Task 4:	Average Trip Duration  How to change measures.</description>
    </item>
    
    <item>
      <title>Correlations and T-tests</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-8/</link>
      <pubDate>Tue, 22 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-8/</guid>
      <description>This project is for people who are interested in statistics, particularly carrying our statistical analysis in Python. In this project will be taking data from the World Bank. They have one data set on science and technology, and that&amp;rsquo;s what we&amp;rsquo;ll be looking at throughout this project.
Data Source: https://www.kaggle.com/datasets/arielfelices/acaf-dataset-collection
Below are the key objectives of this project:  Clean the data and remove null values to prepare it for statistical analysis.</description>
    </item>
    
    <item>
      <title>Lambda Functions in Python</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-7/</link>
      <pubDate>Tue, 22 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-7/</guid>
      <description>In this project we are going to learn about lambda expressions and it&amp;rsquo;s application in python. We are going to start with what is Lambda expression and how we can define it, comparing lambda functions with regular functions in python and at the end we will learn how to use lambda functions for data manipulation and exploration in pandas.
Below is the summary of the tasks performed in this project:  Task 1: What is Lambda expression?</description>
    </item>
    
    <item>
      <title>Python for Data Visualization</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-3/</link>
      <pubDate>Mon, 21 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-3/</guid>
      <description>In this project, we will understand the fundamentals of data visualization with python and we will leverage the power of two important python libraries known as matplotlib and seaborn.
Data Source: https://www.kaggle.com/datasets/arielfelices/python-data-vizz
Below is the summary of the tasks performed in this project:  Task 1: Introduction Task 2: Plot Basic Line Plot Task 3: Plot Scatter Plot Task 4: Plot Pie Chart Task 5: Plot Histogram Task 6: Plot Multiple Plots Task 7: Plot Subplots Task 8: Plot 3D Plots Task 9: Seaborn Scatterplot and Countplot Task 10: Seaborn Pairplot, Displot, and Heatmaps/Correlation  You can find the source data and my codes in any of my Project&amp;rsquo;s Repositories below:</description>
    </item>
    
    <item>
      <title>Learn Data Analysis with Pandas Part 1</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-1/</link>
      <pubDate>Tue, 01 Feb 2022 10:58:08 -0400</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/collections/python-1/</guid>
      <description>TASK 1: DEFINE A PANDAS SERIES  Pandas is a data manipulation and analysis tool that is built on Numpy. Pandas uses a data structure known as DataFrame (think of it as Microsoft excel in Python). DataFrames empower programmers to store and manipulate data in a tabular fashion (rows and columns). Series Vs. DataFrame? Series is considered a single column of a DataFrame.  input:
import pandas as pd Let&amp;rsquo;s define a Python list that contains 5 crypto currencies.</description>
    </item>
    
    <item>
      <title>Building Statistical Models in R: Linear Regression</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-4/</link>
      <pubDate>Thu, 20 Jan 2022 11:14:48 -0400</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-4/</guid>
      <description>Project Objectives In this project, I am going to focus on three learning objectives:
 Build simple and multiple linear regression models. Perform model assessment and interpretation of results. Perform diagnostic checks to test for model assumptions.  Project Structure Below is the summary of the tasks performed in this project:
 Task 1: Getting Started Task 2: Import Packages &amp;amp; the dataset Task 3: Explore the dataset Task 4: Data Visualization Task 5: Model Building Task 6: Model Assessment I Task 7: Model Assessment II Task 8: Model Prediction Task 9: Assumptions Check: Diagnostic Plots Task 10: Multiple Regression  You can find the source data and my codes in my Project&amp;rsquo;s GitHub Repository.</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/about/</guid>
      <description>I&amp;rsquo;m a father of two lovely children and a husband to a very supportive wife. I am currently working as a Data Management Lead for an international company. I am Ariel Felices and I have been actively developing my Data Science skills for the last 12 months. The journey is never easy, but as long as I take it one step at a time, with faith, I know that success awaits.</description>
    </item>
    
  </channel>
</rss>
