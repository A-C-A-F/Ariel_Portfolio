<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Home</title>
    <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/</link>
    <description>Recent content in Projects on Home</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 23 Jul 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://a-c-a-f.github.io/Ariel_Portfolio/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Linear Regression</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-25/</link>
      <pubDate>Sat, 23 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-25/</guid>
      <description>In this project, we will learn how to implement Linear Regression using Python and Numpy. Linear Regression is an important, fundamental concept if you want break into Machine Learning and Deep Learning.
Data Source: Refer to notebook.
Below are the key objectives of this project:  Create a linear model, and implement gradient descent. Train the linear model to fit given data with gradient descent.  Below is the summary of the tasks performed in this project:  Task 1: Introduction Task 2: Dataset Task 3: Initialize Parameters Task 4: Forward Pass Task 5: Compute Loss Task 6: Backward Pass Task 7: Update Parameters Task 8: Training Loop Task 9: Predictions  You can find the source data and my codes in my Project&amp;rsquo;s Repository below:</description>
    </item>
    
    <item>
      <title>Image Denoising with Autoencoders</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-24/</link>
      <pubDate>Wed, 20 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-24/</guid>
      <description>In this project, we will learn the basics of image noise reduction with auto-encoders. Auto-encoding is an algorithm to help reduce dimensionality of data with the help of neural networks.
Data Source: MNIST dataset
Below are the key objectives of this project:  Develop an understanding of Auto-encoders. Be able to apply Image Noise Reduction with Auto-encoders.  Below is the summary of the tasks performed in this project:  Task 1: An introduction to the problem, as well as a summary of the imports we will need.</description>
    </item>
    
    <item>
      <title>Dimensionality Reduction</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-23/</link>
      <pubDate>Mon, 18 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-23/</guid>
      <description>In this project, we will introduce the theory behind an autoencoder (AE), its uses, and its advantages over PCA, a common dimensionality reduction technique.
Data Source: We will use the make_blobs function from sklearn.dataset to create our own dataset.
Below are the key objectives of this project:  How to create a dummy dataset of high dimensionality, and reduce its dimensionality using PCA. How an autoencoder works, and how it is essentially a nuanced neural network.</description>
    </item>
    
    <item>
      <title>CIFAR-10 Image Classification</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-22/</link>
      <pubDate>Fri, 08 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-22/</guid>
      <description>In this project, we will build, train, and test a deep neural network model to classify low-resolution images containing airplanes, cars, birds, cats, ships, and trucks in Keras and Tensorflow 2.0. We will use Cifar-10 which is a benchmark dataset that stands for the Canadian Institute For Advanced Research (CIFAR) and contains 60,000 32x32 color images
Data Source: https://www.cs.toronto.edu/~kriz/cifar.html
Below are the key objectives of this project:  Understand the fundamentals of Convolutional Neural Networks (CNNs) Build, train and test Convolutional Neural Networks in Keras and Tensorflow 2.</description>
    </item>
    
    <item>
      <title>Basic-Image-Classification</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-21/</link>
      <pubDate>Thu, 07 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-21/</guid>
      <description>In this project, we will create and train a model that takes an image of a hand written digit as input and predicts the class of that digit, that is, it predicts the digit or it predicts the class of the input image. Through this project, will learn the basics of using Keras with TensorFlow as its backend and use it to solve a basic image classification problem.
Data Source: MNIST data</description>
    </item>
    
    <item>
      <title>ML Algorithms</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-20/</link>
      <pubDate>Wed, 06 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-20/</guid>
      <description>In this project, we will train several classification algorithms. Machine learning algorithms help companies analyze customer attrition rate based on several factors which includes various services subscribed by the customers, tenure rate, gender, senior citizen, payment method, etc..
Data Source: https://www.kaggle.com/datasets/blastchar/telco-customer-churn
Below are the key objectives of this project:  Understand the theory and intuition behind Logistic Regression, Support Vector Machine, Random Forest, K-Nearest Neighbor, and Naive Bayes Classifier models.</description>
    </item>
    
    <item>
      <title>Artificial Neural Nets</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-19/</link>
      <pubDate>Fri, 01 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-19/</guid>
      <description>In this project, we will build and train a simple deep neural network model to predict the likelihood of a liability customer (depositor) buying personal loans based on customer features like age, experience, income, locations, family, education, existing mortgage, and credit card, etc..
Lenddo is a leading startup that uses advanced machine learning to analyze over 12,000+ features from various sources of data to predict an individual&amp;rsquo;s creditworthiness (e.g.: social media account use, geolocation data, etc.</description>
    </item>
    
    <item>
      <title>Classification Regression Models</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-18/</link>
      <pubDate>Sat, 25 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-18/</guid>
      <description>In this project, we will explore how we can develop an intepretable and explainable machine learning application on the example of classification regression models such as a Decision Tree and Random Forest Classifiers.
Data Source: https://www.kaggle.com/datasets/shikhar07/fifa-2018-dataset
Below are the key objectives of this project:  Create an intepretable machine learning application in Python. Select, run, evaluate and compare two different classification regression models. Extract, which features are the most important ones for our classification regressors.</description>
    </item>
    
    <item>
      <title>Regression-using-TensorFlow</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-17/</link>
      <pubDate>Thu, 16 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-17/</guid>
      <description>In this project, We are looking to solve a regression problem. With the help of a neural network model and some data in a regression task, we train the neural network to predict a continuous value, given a set of input features. This is different from classification. In classification problems, we train a model to predict discrete values or classes.
Data Source: https://www.kaggle.com/datasets/mubin2509/housepricedata
Given some data with these features and the corresponding price for various houses, we will create and train a model that will give us fairly accurate price predictions for new, unseen data.</description>
    </item>
    
    <item>
      <title>Logistic Regression with Python</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-16/</link>
      <pubDate>Fri, 10 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-16/</guid>
      <description>Unlike in the case of linear regression, where we&amp;rsquo;re trying to predict a real and continuous valued output, logistic regression is a classification algorithm and it tries to predict a discrete set of class labels for the given input.
Data Source: https://www.kaggle.com/datasets/arielfelices/acaf-dataset-collection?select=DMV_Written_Tests.csv
Our dataset is DMV_Written_Tests.csv. This dataset is comprised of written test scores. We will be trying to predict if a person with those test scores passed or failed.</description>
    </item>
    
    <item>
      <title>Deep Learning for Real Estate Price Prediction</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-15/</link>
      <pubDate>Fri, 03 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-15/</guid>
      <description>In this project, we will predict real estate prices using artificial neural networks. Dataset includes house sale prices for King County in USA and homes that are sold in the time period between May 2014 and May 2015.
Data Source: https://www.kaggle.com/harlfoxem/housesalesprediction
Below is the summary of the tasks performed in this project:  Task 1: Understand the Problem Statement and Business Case Task 2: Import Libraries and Datasets Task 3: Perform Data Visualization Task 4: Perform Data Cleaning and Feature Engineering Task 5: Train a Deep Learning Model with Limited Number of Features Task 6: Evaluate Trained Deep Learning Model Performance Task 7: Train and Evaluate a Deep Learning Model with Increased Number of Features  You can find the source data and my codes in any of my Project&amp;rsquo;s Repositories below:</description>
    </item>
    
    <item>
      <title>Python and Networkx</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-14/</link>
      <pubDate>Sat, 28 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-14/</guid>
      <description>In this project, we&amp;rsquo;re going to work with Facebook Friends Network graph. In this graph, each nodes represent a Facebook account, and the edge between two nodes indicate that those two accounts are friends. We are going to load this data set and visualized it using Python networkX module. The goal of this analysis is to explore some important characteristics of this graph, such as finding most important nodes on the graph.</description>
    </item>
    
    <item>
      <title>Neural Network Visualizer Web App</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-13/</link>
      <pubDate>Wed, 18 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-13/</guid>
      <description>In this project, we will use a simple neural network with two hidden layers and one output layer. We will visualized the output values of only nodes of all these layers. Through this project, we will learn how to create a simple server, that flask to serve our neural network model for inference, a simple web application with streamlit.
Below are the key objectives of this project:  Create a model server with Flask and Keras Create a web application with Streamlit Utilize Keras&amp;rsquo; functional API  Below is the summary of the tasks performed in this project:  Task 1: Load Libraries and Data Task 2: Data Normalization Task 3: Create and Train a Neural Network Model Task 4: Create a Model Server with Flask Task 5: Create a Streamlit Web Application  You can find the source data and my codes in my Project&amp;rsquo;s GitHub Repository.</description>
    </item>
    
    <item>
      <title>Sentiment Analysis Using NLP</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-12/</link>
      <pubDate>Wed, 11 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-12/</guid>
      <description>In this project, we will build a machine learning model to analyze thousands of reviews to predict customer sentiment. Artificial Intelligence and Machine Learning-based sentiment analysis is crucial for companies to automatically predict whether their customers are happy or not. This project is important and directly applicable to any company that has online presence. These algorithms could be used to automatically detect customer sentiment from their reviews.
Data Source: https://www.</description>
    </item>
    
    <item>
      <title>Support Vector Machine Classification in Python</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-11/</link>
      <pubDate>Wed, 04 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-11/</guid>
      <description>In this project, we will build a support vector machine (SVM) algorithm in python with classification. We will try to predict whether a customer will purchase a particular car in the future given his age and current estimated salary. The datasaet contains the following features:
 User ID Gender Age EstimatedSalary Purchased (means if the person purchased a car before)  Data Source: https://www.kaggle.com/datasets/arielfelices/acaf-dataset-collection
Below are the key objectives of this project:  Understand the basics of Support Vector Machines in Classification using a real world example.</description>
    </item>
    
    <item>
      <title>Resume Selector</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-9/</link>
      <pubDate>Sun, 01 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-9/</guid>
      <description>In this project, we will build a naïve based model to predict whether given resume text is flagged or not. Simply put, if the resume is flagged, that means that the applicant is invited to interview.
Data Source: https://www.kaggle.com/samdeeplearning/deepnlp
Below are the key objectives of this project:  Apply python libraries to import and visualize datasets Perform exploratory data analysis and plot word-cloud Perform text data cleaning such as removing punctuation and stop words Perform tokenization using count vectorizer Train Naïve Bayes classifier models using Scikit-Learn to perform classification Evaluate the performance of trained Naïve Bayes Classifier model using confusion matrices  Below is the summary of the tasks performed in this project:  Task 1: Understand the Problem Statement and Business Case Task 2: Import libraries and datasets Task 3: Perform exploratory data analysis Task 4: Perform data cleaning Task 5: Visualize cleaned datasets Task 6: Prepare the data by applying count vectorization Task 7: Train a Naïve Bayes classifier model Task 8: Assess trained model performance  You can find the source data and my codes in any of my Project&amp;rsquo;s Repositories below:</description>
    </item>
    
    <item>
      <title>Predicting the Weather</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-10/</link>
      <pubDate>Fri, 29 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-10/</guid>
      <description>In this project, we&amp;rsquo;re going to work with a set of data that comes from the Australian government. This contains nearly nine years&amp;rsquo; worth of daily weather data from a station in Perth.
Data Source: https://www.kaggle.com/datasets/arielfelices/weatherperth
Below is the summary of the tasks performed in this project:  Task 1: Load a dataset from file Task 2: Process a dataset to make it compatible with a neural network Task 3: Split our dataset into training and testing sets Task 4: Train a neural network and make predictions Task 5: Optimize a neural network  You can find the source data and my codes in any of my Project&amp;rsquo;s Repositories below:</description>
    </item>
    
    <item>
      <title>Support Vector Machines in Python</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-8/</link>
      <pubDate>Wed, 27 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-8/</guid>
      <description>In this lesson we will built this Support Vector Machine for classification using scikit-learn and the Radial Basis Function (RBF) Kernel. Our training data set contains continuous and categorical data from the UCI Machine Learning Repository to predict whether or not a patient has heart disease.
Below are the key objectives of this project:  Importing data into, and manipulating a pandas dataframe. Identifying and dealing with missing data. Formatting the data for a support vector machine, including One-Hot Encoding Optimizing parameters for the radial basis function and classification Building, evaluating, drawing and interpreting a support vector machine  Below is the summary of the tasks performed in this project:  Task 1: Import the modules that will do all the work Task 2: Import the data Task 3: Missing Data Part 1: Identifying Missing Data Task 4: Missing Data Part 2: Dealing With Missing Data Task 5: Format Data Part 1: Split the Data into Dependent and Independent Variables Task 6: Format the Data Part 2: One-Hot Encoding Task 7: Format the Data Part 3: Centering and Scaling Task 8: Build A Preliminary Support Vector Machine Task 9: Optimize Parameters with Cross Validation Task 10: Building, Evaluating, Drawing, and Interpreting the Final Support Vector Machine  You can find the source data and my codes in any of my Project&amp;rsquo;s Repositories below:</description>
    </item>
    
    <item>
      <title>Predict Employee Turnover with scikit-learn</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-7/</link>
      <pubDate>Mon, 25 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-7/</guid>
      <description>Employee turnover analytics is the process of assessing your turnover rates in an attempt to predict and reduce future employee turnover. Machine Learning models can enable companies to identify variables and features and also bonuses and incentives that predict turnover within their own organization and business.
The dataset contains employees’ profiles of a large companies where each row is a data of unique employee. The dataset is downloaded from Kaggle but initially put together by a very large multinational corporation.</description>
    </item>
    
    <item>
      <title>Fake News Detection with Machine Learning</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-6/</link>
      <pubDate>Sat, 23 Apr 2022 11:25:05 -0400</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-6/</guid>
      <description>Project Objectives In this project, I am going to focus on the following learning objectives:
 Apply python libraries to import and visualize datasets Perform exploratory data analysis and plot word-cloud Perform text data cleaning such as removing punctuation and stop words Understand the concept of tokenizer. Perform tokenizing and padding on text corpus to feed the deep learning model. Understand the theory and intuition behind Recurrent Neural Networks and LSTM Build and train the deep learning model Access the performance of the trained model  Project Structure  Task 1: Understand the Problem Statement and business case Task 2: Import libraries and datasets Task 3: Perform Feature Engineering Task 4: Perform Data Cleaning Task 5: Visualize the cleaned data Task 6: Prepare the data by tokenizing and padding Task 7: Understand the theory and intuition behind Recurrent Neural Networks and LSTM Task 8: Build and train the model Task 9: Assess trained model performance  You can find the source data and my codes in my Project&amp;rsquo;s GitHub Repository.</description>
    </item>
    
    <item>
      <title>Customer Market Segmentation</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-3/</link>
      <pubDate>Thu, 14 Apr 2022 11:25:05 -0400</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-3/</guid>
      <description>Project Objectives In this project, I am going to focus on the following learning objectives:
 Understand how to leverage the power of machine learning to transform marketing departments and perform customer segmentation. Apply Python libraries to import and visualize dataset images. Understand the theory and intuition behind k-means clustering machine learning algorithm. Learn how to obtain the optimal number of clusters using the elbow method. Apply Scikit-Learn library to find the optimal number of clusters using elbow method.</description>
    </item>
    
    <item>
      <title>Multiple Linear Regression</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-2/</link>
      <pubDate>Mon, 11 Apr 2022 11:00:59 -0400</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-2/</guid>
      <description>In this project, we will build and evaluate multiple linear regression models using Python. I will use scikit-learn to calculate the regression, while using pandas for data management and seaborn for plotting. The data for this project consists of the very popular Advertising dataset to predict sales revenue based on advertising spending through media such as TV, radio, and newspaper.
Project Objectives The key objective of this project is to learn the following skills:</description>
    </item>
    
    <item>
      <title>Titanic Survival Prediction</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-5/</link>
      <pubDate>Fri, 01 Apr 2022 11:25:05 -0400</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-5/</guid>
      <description>Project Objectives  Understand the theory and intuition behind logistic regression classifier models Build, train and test a logistic regression classifier model in Scikit-Learn Perform data cleaning, feature engineering and visualization  The sinking of the Titanic is one of the most well-known tragedies in modern history. The tragedy took place on April 15, 1912. The Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers.</description>
    </item>
    
    <item>
      <title>Univariate Linear Regression</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-1/</link>
      <pubDate>Mon, 28 Mar 2022 10:58:08 -0400</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-1/</guid>
      <description>Project Objectives My objective in this project is to learn the following skills:
 Implement the gradient descent algorithm from scratch. Perform univariate linear regression with Numpy and Python. Create data visualizations and plots using matplotlib.  Project Structure Below is the summary of the tasks performed in this project:
 Task 1: Load the Data and Libraries Task 2: Visualize the Data Task 3: Compute the Cost 𝐽(𝜃) Task 4: Implement Gradient Descent from scratch in Python Task 5: Visualizing the Cost Function J(𝜃) Task 6: Plotting the Convergence Task 7: Training Data with Univariate Linear Regression Fit Task 8: Inference using the optimized 𝜃 values  You can find the source data and my codes in any of my Project&amp;rsquo;s Repositories below:</description>
    </item>
    
    <item>
      <title>Building Statistical Models in R: Linear Regression</title>
      <link>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-4/</link>
      <pubDate>Thu, 20 Jan 2022 11:14:48 -0400</pubDate>
      
      <guid>https://a-c-a-f.github.io/Ariel_Portfolio/post/chapter-4/</guid>
      <description>Project Objectives In this project, I am going to focus on three learning objectives:
 Build simple and multiple linear regression models. Perform model assessment and interpretation of results. Perform diagnostic checks to test for model assumptions.  Project Structure Below is the summary of the tasks performed in this project:
 Task 1: Getting Started Task 2: Import Packages &amp;amp; the dataset Task 3: Explore the dataset Task 4: Data Visualization Task 5: Model Building Task 6: Model Assessment I Task 7: Model Assessment II Task 8: Model Prediction Task 9: Assumptions Check: Diagnostic Plots Task 10: Multiple Regression  You can find the source data and my codes in my Project&amp;rsquo;s GitHub Repository.</description>
    </item>
    
  </channel>
</rss>
